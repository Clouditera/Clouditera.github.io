---
layout:     post
title:      "【论文速读】| JADE：用于大语言模型的基于语言学的安全评估平台"
date:       2024-08-12 15:00:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
tags:
    - Security
    - AIGC
    - 论文速读
---


![这是一张图片](https://www.gptsecurity.info/img/in-post/0807/01.jpg)


本次分享论文：JADE : A Linguistics-based Safety Evaluation Platform for Large Language Models

## 基本信息

**原文作者**：Mi Zhang, Xudong Pan, Min Yang

**作者单位**：Whitzard-AI, System Software and Security Lab @ Fudan University

**关键词**：Certificates, TEQIP Participation, LLM Safety Testing

**原文链接**：https://arxiv.org/abs/2311.00286

**开源代码**：https://github.com/whitzard-ai/jade-db

## 论文要点

**论文简介**：JADE是一个创新的模糊测试平台，专注于增强语言复杂性以挑战大语言模型的安全性。它针对三组不同的语言模型：八个开源中文模型、六个商业中文模型和四个商业英文模型，生成了三个安全基准，成功触发70%的不安全内容生成。JADE利用诺姆·乔姆斯基的转换生成语法理论，通过生成和转换规则增加问题复杂性，直至突破模型的安全限制。其核心优势在于识别语言模型无法完全覆盖的恶意语义。JADE还集成了主动学习算法，通过少量标注数据不断优化评估模块，提高与人类专家判断的一致性。

**研究目的**：本研究的目标在于探寻大语言模型（LLMs）的安全边界。JADE 借助诺姆·乔姆斯基的生成语法理论，能够自动把自然问题转变为愈发复杂的句法结构，从而突破其安全防线。研究者的核心观点为：鉴于人类语言的复杂性，当下大多数最为出色的 LLMs 很难从数量无限的不同句法结构中识别出始终不变的有害意图。所以，JADE 致力于通过提升问题的句法复杂性，揭露 LLMs 在应对复杂句法形式时的共同弱点，进而增强安全评估的系统性。

**研究贡献**：

1. **有效性**：JADE 具备出色的有效性，能够把原本违规率约为 20%的种子问题转变为高度关键且不安全的问题，使 LLMs 的平均违规率大幅提升至 70%以上，切实有效地探索了 LLMs 的语言理解和安全边界。

2. **可转移性**：JADE 生成的高威胁测试问题具有良好的可转移性，能够在几乎所有开源 LLMs 中触发违规行为。例如，在 JADE 生成的中文开源大模型安全基准数据集中，有 30%的问题能够同时触发八个著名的中文开源 LLMs 的违规行为。

3. **自然性**：JADE 通过语言变异生成的测试问题几乎不改变原问题的核心语义，很好地保持了自然语言的特性。与此形成鲜明对比的是，LLMs 的越狱模板引入了大量语义无关的元素或乱码字符，呈现出强烈的非自然语言特性，容易被 LLMs 开发者的定向防御措施所针对。
   
## 引言

目前，AIGC 在诸多关键应用领域迅速发展，但因其训练数据的质量参差不齐，包括难以清理的不安全文本，致使预训练的 LLMs 如 GPT-3 易生成不安全内容，如何抑制其不安全生成行为成为构建 3H 原则生成 AI 的首要挑战。


![这是一张图片](https://www.gptsecurity.info/img/in-post/0812/04.png)

为探索 LLMs 的安全边界，研究者打造了综合的目标语言模糊测试平台 JADE。该平台依据乔姆斯基的生成语法理论，能自动将自然问题转化为更复杂的句法结构，以突破安全防线。它通过智能调用生成和变换规则，自动增长并变换给定问题的句法树，直至目标 LLMs 生成不安全内容。评估表明，多数著名的对齐 LLMs 在少量变换/生成步骤后就会被突破，证明了该语言模糊测试程序的高效性。此外，JADE 不仅实现了自动评估模块，采用主动提示调优理念减少手动标注需求，还系统化了现有对齐 LLMs 的失效模式，分析了它们处理人类语言复杂性方面的局限性。

## 研究背景

生成式人工智能（AIGC）的安全性应予以优先考量。在安全原则当中，一个基本的要求便是生成的内容应当无害，这实际上在 ChatGPT 以及其他对齐的 LLM 的早期设计中就已经达成。AIGC 所生成的内容不应违背伦理标准，也不应产生负面的社会影响。正因如此，监督微调（SFT）、人类反馈强化学习（RLHF）、AI 反馈强化学习（RLAIF）等策略被提出，以抑制不安全的生成行为。研究者的工作探讨了怎样评估和测试 AIGC 是否真正达成并满足了安全原则。

## Preliminary

乔姆斯基的生成语法理论对人类语言的语法结构进行了解释，提出了一套用以描述如何由较小的句子成分生成一个句子的规则。比如，一条基本的生成规则是“句子能够重写为名词短语和动词短语”。借由递归调用这些规则，能够构建出愈发复杂的问题。

在变换语法方面，乔姆斯基的理论主张存在两层用于表示人类语言结构的层次，即深层结构和表层结构。通过变换规则，可以把一个问题的成分移动至另一个合适的位置，或者将原始关键词替换成一些不常见的同义词，进而增加句法的复杂性。

## JADE

JADE 是一个基于语言学的模糊测试平台，其目的在于评估大语言模型（LLMs）的安全性。该平台运用乔姆斯基的生成语法理论，通过提高种子问题的句法复杂性，对 LLMs 的安全防线进行系统性测试。JADE 所生成的测试问题能够持续地促使多种 LLMs 生成有害内容，平均不安全生成比例高达 70%。这一平台通过改变原始问题的句法结构，让问题变得更为复杂，进而突破 LLMs 的安全防线。JADE 的评估结果表明，生成的问题在多个 LLMs 之间具备很强的可转移性，同时保持了问题的自然语言特性。此外，JADE 还引入了主动提示调优技术，降低了手动标注的需求，并且提升了评估结果的准确性。总之，JADE 通过揭示 LLMs 在处理复杂句法结构时的共同弱点，为 LLMs 的安全评估提供了一种行之有效的方法。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0812/05.png)

## 评估结果

JADE 的评估结果表明，该平台在显著提升种子问题触发不安全生成的效果方面表现出色。实验显示，JADE 能够将原本违规率仅约 20%的种子问题转化为违规率高达 70%以上的关键问题。该测试覆盖了多个主流的 LLMs，包括开源和商业模型，结果证实生成的问题在不同 LLMs 之间具有很强的可转移性，大多数 JADE 生成的问题能够同时引发多个 LLMs 的违规行为。此外，这些生成的问题在流畅性和语义保持方面表现优异，与种子问题相比，较好地保持了自然语言特性，这也证明了 JADE 在增加语言复杂性方面的有效性。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0812/06.png)

## 更多相关工作

现有的相关工作主要聚焦于探讨大语言模型（LLMs）的失效模式以及语言复杂性方面所面临的挑战。研究显示，LLMs 在处理复杂句法结构时，常常呈现出逻辑不一致性、对抗性鲁棒性匮乏以及容易分心等问题。比如，Fluri 等人发现，LLMs 在应对否定和改写问题时，常常会产生逻辑错误。另外，此前的研究还表明，LLM 在遭遇字符级扰动（例如添加、删除或者重复字符）、词汇替换（使用同义词替换词汇）以及句法变形（诸如风格转换）时，表现出较差的鲁棒性。Shi 等人则指出，当在问题描述中添加无关信息时，LLM 的表现会显著降低，体现出容易受到干扰的特性。相较而言，JADE 通过语言变异生成的问题，在维持核心语义以及自然语言特性方面具备显著优势，为 LLM 的安全评估提供了更为系统、更为有效的办法。

## 论文结论

本文提出了一个基于语言学的 LLMs 安全评估平台 JADE，该平台通过提升问题的句法复杂性，有效地探索了 LLMs 的语言理解和安全边界。实验结果显示，JADE 生成的问题在多个 LLMs 当中具有很强的可转移性，并且在流利性和语义保持方面有着出色的表现。未来的工作会进一步对 JADE 的生成规则和评估模块进行优化，从而提高其在更广泛应用场景里的适用性。 

原作者：论文解读智能体

校对：小椰风






