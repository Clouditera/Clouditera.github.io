---
layout:     post
title:      "第61期 | GPTSecurity周报"
date:       2024-08-09 19:00:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
tags:
    - Security
    - AIGC
    - GPTSecurity周报
---


![这是一张图片](https://www.gptsecurity.info/img/in-post/0807/01.jpg)


GPTSecurity是一个涵盖了前沿学术研究和实践经验分享的社区，集成了生成预训练Transformer（GPT）、人工智能生成内容（AIGC）以及大语言模型（LLM）等安全领域应用的知识。在这里，您可以找到关于GPT/AIGC/LLM最新的研究论文、博客文章、实用的工具和预设指令（Prompts）。现为了更好地知悉近一周的贡献内容，现总结如下。


## Security Papers



1. **RedAgent：使用具有上下文感知的自主语言智能体对 大语言模型进行红队测试**
   
   简介：研究者们开发了名为RedAgent的多智能体大语言模型系统，以应对LLMs在现实世界应用中的安全挑战。RedAgent通过抽象现有的越狱攻击策略，生成上下文感知的提示，有效提高了红队测试的效率和准确性。系统通过自我反思和持续学习，能在特定上下文中实现有效的越狱。实验结果表明，RedAgent能在五次查询内越狱大多数黑盒LLMs，效率是传统方法的两倍。此外，RedAgent还发现了60个针对GPTs应用的严重漏洞，并已与相关公司沟通修复。

   *链接：https://arxiv.org/abs/2407.16667* 



2. **在大语言模型（LLMs）时代探索自动加密API误用检测**
   
   简介：本文提出了一个评估大语言模型（LLMs）在检测加密API误用方面的系统性框架，通过分析11,940份报告，揭示了LLMs的不稳定性，这些报告中过半数为误报。研究者们通过限定问题范围和利用LLMs的自我纠正能力，显著提升了检测的准确性，实现了接近90%的检测率，超越了传统方法。同时，识别了LLMs在加密知识理解和代码语义解释上的不足，并基于此开发了一套基于LLM的工作流程，成功在开源代码库中发现63个现实世界的加密误用，其中46个已被社区认可，23个正在修复，6个已解决。

   *链接：https://arxiv.org/abs/2407.16576*


3. **OriGen：通过代码到代码的增强和自我反思来增强 RTL 代码生成**  
 
   简介：研究者们推出了OriGen，一个具备自我反思和数据增强功能的完全开源框架，专门用于生成高质量、大规模的寄存器传输级（RTL）代码。他们创新性地提出了一种代码到代码增强方法，通过知识蒸馏技术提升开源RTL代码数据集的质量。OriGen还能利用编译器反馈进行自我反思，自动纠正语法错误，这一能力得益于一个精心构建的、包含全面样本的数据集。
实验结果显示，OriGen在RTL代码生成任务上明显超越其他开源方案，在VerilogEval-Human基准测试中比之前最佳的LLM提升了9.8%。同时，在评估自我反思能力的基准测试中，OriGen的性能更是超越了GPT-4达18.1%，展现了其在自我反思和错误修正方面的卓越能力。

   *链接：https://arxiv.org/abs/2407.16237*


4. **静态应用程序安全测试工具与大语言模型在代码库级别漏洞检测中的比较**
   
   简介：研究者们对15种不同的静态应用程序安全测试（SAST）工具和12种流行或最先进的开源大语言模型（LLMs）进行了比较，目的是检测Java、C和Python三种流行编程语言代码库中的软件漏洞。研究发现，SAST工具的漏洞检测率较低，但误报率也相对较低；而LLMs虽然能够检测到高达90%至100%的漏洞，却伴随着较高的误报率。研究者们进一步探索了将SAST工具和LLMs集成的方法，以期在一定程度上弥补各自的不足。这项分析不仅展示了软件漏洞检测技术的最新进展，也为未来的研究方向提供了宝贵的指导。

   *链接：https://arxiv.org/abs/2407.16235*


5. **VidyaRANG：由大语言模型驱动的基于对话学习的平台**
   
   简介：研究者们设计了一个创新平台，以提供定制化的学习体验，旨在解决传统搜索引擎信息过载和大语言模型（LLMs）在处理敏感信息时的局限。该平台特别强调互动性和提问功能，结合知识增强检索技术，帮助学习者快速获得精确信息并深入理解学习内容。
在技术实现上，平台前端采用Streamlit和React框架，优化用户界面和交互体验。后端则利用AWS EC2实例安全存储API密钥，并通过SSL证书增强数据传输的安全性。研究者们还在开发基于Android Studio的移动应用，计划将其发布到Play商店，以提升平台的移动可访问性和用户体验。

   *链接：https://arxiv.org/abs/2407.16209*
   


6. **基于分析的大语言模型越狱攻击**
   
   
   简介：研究者们深入探究了大语言模型（LLMs）在越狱攻击面前的脆弱性，并提出了一种称为基于分析的越狱（Analyzing-based Jailbreak, ABJ）的新方法。ABJ利用了LLMs日益增强的分析和推理能力，揭示了它们在处理分析型任务时的潜在安全漏洞。通过对不同开源和闭源的LLMs进行详尽的ABJ评估，研究者们发现在GPT-4-turbo-0409模型上，攻击成功率（ASR）达到了94.8%，攻击效率（AE）为1.06，这表明了ABJ在攻击效果和效率上均达到了先进水平。此项研究凸显了提升LLMs安全性的紧迫性，以减少这些强大工具被滥用的风险。

   *链接：https://arxiv.org/abs/2407.16205*




