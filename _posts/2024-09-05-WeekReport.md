---
layout:     post
title:      "第66期|GPTSecurity周报"
date:       2024-09-05 16:00:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
catalog: true
tags:
    - Security
    - AIGC
    - GPTSecurity周报
---


![这是一张图片](https://www.gptsecurity.info/img/in-post/0807/01.jpg)

GPTSecurity是一个涵盖了前沿学术研究和实践经验分享的社区，集成了生成预训练Transformer（GPT）、人工智能生成内容（AIGC）以及大语言模型（LLM）等安全领域应用的知识。在这里，您可以找到关于GPT/AIGC/LLM最新的研究论文、博客文章、实用的工具和预设指令（Prompts）。现为了更好地知悉近一周的贡献内容，现总结如下。

## Security Papers

#### 利用高级大语言模型增强小语言模型：一种可解释的知识蒸馏方法

简介：高级大语言模型如 GPT-4 和 LlaMa 3 性能卓越但成本高、难自托管，存在安全隐私问题。研究者引入一种可解释的知识蒸馏新方法，以增强可自托管的小型经济语言模型性能。在构建客户服务代理场景中，该方法不同于传统知识蒸馏，采用“策略”教学，由教师提供策略提升学生在不同场景表现，在“场景生成”和“改进策略”步骤间交替，创建定制场景库和优化策略，仅需黑盒访问模型，不操纵参数。在客户服务应用中，该方法提高性能且策略可转移到训练集外。其可解释性利于通过人工审核防范潜在危害。

*链接：https://arxiv.org/abs/2408.07238*. 

#### 评估基于大型语言模型的个人信息提取及其对策

简介：研究者进行了一项系统测量研究，对基于大语言模型（LLM）的个人信息提取及对策进行基准测试。他们提出基于 LLM 的提取攻击框架，收集了包括 GPT-4 生成的合成数据集和两个真实世界数据集。引入基于“提示注入”的新型缓解策略，并使用 10 个 LLM 和三个数据集进行基准测试。主要发现有：攻击者可能滥用 LLM 准确提取个人信息，LLM 在提取上优于传统方法，而提示注入能在很大程度上减轻风险且优于传统对策。其代码和数据可在特定网址获取。这为防范个人信息被大规模提取提供了重要参考，有助于提升信息安全防护水平。

*链接：https://arxiv.org/abs/2408.07291*

#### 用于高效入侵检测系统的 Transformer 和大语言模型：全面综述

简介：本综述全面分析了 Transformer 和大语言模型在网络威胁检测系统中的应用。概述了论文选择方法和文献计量分析以评估现有研究，讨论了 Transformer 基本原理及相关网络攻击背景和常用数据集。探索了其在入侵检测系统中的应用，涵盖多种架构和新兴方法。还探讨了在不同环境和应用中的实施情况，包括计算机网络、物联网等。阐述了该领域研究挑战和未来方向，确定可解释性等关键问题。最后，结论总结研究结果，强调其在增强网络威胁检测能力的重要性，同时概述了进一步研究和开发的潜在途径，为提升网络安全提供了重要参考，有助于推动相关技术的发展和应用，以更好地应对不断演变的网络威胁。

*链接：https://arxiv.org/abs/2408.07583*

#### CodeMirage：大语言模型生成代码中的幻觉

简介：研究者指出大语言模型在程序生成和无代码自动化中有巨大潜力，但易产生幻觉，代码生成中也存在类似现象，如语法逻辑错误、安全漏洞等。为此，他们首次研究大语言模型生成代码中的幻觉，引入代码幻觉定义和分类法，提出首个基准数据集 CodeMirage，包含 GPT-3.5 为 Python 编程问题生成的幻觉代码片段。通过实验发现 GPT-4 在 HumanEval 数据集上表现最佳，在 MBPP 数据集上与微调后的 CodeBERT 基线相当。最后，讨论了各种缓解代码幻觉的策略并总结工作，为提高代码生成质量和可靠性提供了方向，有助于推动大语言模型在代码生成领域的更好应用。

*链接：https://arxiv.org/abs/2408.08333*

#### 基于智能控制的 GPT 增强型强化学习在车辆调度中的应用

简介：随着城市居民对出行质量要求提高，车辆调度在在线网约车服务中愈发重要。但当前车辆调度系统难以应对城市交通动态复杂性，导致乘客出行困难、司机接不到单，城市交通服务质量下降。为此，本文引入 GARLIC，即基于智能控制的 GPT 增强型强化学习车辆调度框架。它利用多视图图捕捉交通状态，学习考虑司机行为的动态奖励函数，并集成经自定义损失函数训练的 GPT 模型以实现高精度预测和优化调度策略。在两个真实世界数据集上的实验表明，GARLIC 能降低车辆空载率且与司机行为一致，为提升车辆调度效率和城市交通服务质量提供了新方法，有望改善网约车服务的运营效果。

*链接：https://arxiv.org/abs/2408.10286*

#### 大语言模型作为端到端的安全代码生产者表现如何？

简介：研究者指出，以GPT-4为代表的大语言模型（LLMs）的飞速发展彻底改变了软件工程的格局，使这些模型成为现代开发实践的核心。随着预期这些模型将发展成为软件开发中的主要和可信赖工具，确保它们生成的代码的安全性变得至关重要。研究者对大语言模型生成安全代码的能力进行了系统研究，研究了 GPT-3.5 和 GPT-4 对包括自身在内的四种流行模型生成代码的漏洞识别和修复能力。通过审查 4900 段代码发现，大语言模型缺乏场景安全风险意识，生成超 75%有漏洞代码，且难以准确识别自身生成代码的漏洞，修复其他模型代码成功率为 33.2% - 59.6%，修复自身代码表现不佳。为解决单次修复局限性，开发了轻量级工具，在语义分析引擎辅助下，将修复成功率提高到 65.9% - 85.5%。为提升大语言模型生成安全代码的能力提供了思路。

*链接：https://arxiv.org/abs/2408.10495*


![secgeek-foot](https://www.gptsecurity.info/img/secgeek-foot.png)
