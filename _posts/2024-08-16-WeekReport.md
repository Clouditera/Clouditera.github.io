---
layout:     post
title:      "第53期|GPTSecurity周报"
date:       2024-08-16 16:00:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
catalog: true
tags:
    - Security
    - AIGC
    - GPTSecurity周报
---


![这是一张图片](https://www.gptsecurity.info/img/in-post/0807/01.jpg)

GPTSecurity是一个涵盖了前沿学术研究和实践经验分享的社区，集成了生成预训练Transformer（GPT）、人工智能生成内容（AIGC）以及大语言模型（LLM）等安全领域应用的知识。在这里，您可以找到关于GPT/AIGC/LLM最新的研究论文、博客文章、实用的工具和预设指令（Prompts）。现为了更好地知悉近一周的贡献内容，现总结如下。


## Security Papers



#### WitheredLeaf: 利用大语言模型 (LLM) 发现实体不一致性漏洞

简介：实体不一致性漏洞（EIBs）是语法正确但程序实体使用不当的错误，通常影响安全且难以发现。传统检测方法如静态分析和动态测试难以应对EIBs的多样性和上下文依赖性。然而，利用大语言模型（LLMs）的语义理解能力，自动EIB检测变得可行。研究表明，尽管GPT-4有潜力，但其召回率和精确度有限。为此，研究者开发了WitheredLeaf系统，通过特定于代码的小型语言模型提高精确度和召回率。在154个高星Python和C的GitHub存储库上测试，WitheredLeaf识别出123个新缺陷，其中45%可干扰程序运行，69个修复提案中有27个已合并。

*链接：https://arxiv.org/pdf/2405.01668*


#### 中性提示会导致不安全的代码吗？FormAI-v2 数据集：标记由大语言模型生成的代码中的漏洞

简介：本研究对大语言模型（LLMs）进行比较分析，探讨它们在中性零样本提示下编写简单的C程序时产生安全漏洞的可能性。研究填补了现有文献中关于这些模型生成代码安全属性的空白。研究者基于FormAI-v2数据集，包含265,000个由不同LLMs生成的C程序，使用ESBMC进行形式验证，发现至少63.47%的程序存在漏洞。结果表明，模型间差异不大，因为所有模型都显示出类似的编码错误。研究强调，LLMs在代码生成上虽有潜力，但在生产环境中部署其输出需进行风险评估和验证。

*链接：https://arxiv.org/pdf/2404.18353*


#### 大语言模型（LLMs）在网络防御中的全面概述：机遇与方向

简介：大语言模型（LLMs）在数据密集型应用中取得了显著进展，能够编码上下文并提供对下游任务的强大理解能力。这种能力有助于识别网络威胁异常、增强事件响应和自动化安全操作。本文概述了LLMs在网络防御领域的最新活动，并分类讨论了威胁情报、漏洞评估、网络安全、隐私保护、意识培训、自动化和道德指导等方面。介绍了从Transformers到GPT的LLMs发展基本概念，并分析了各部分的优势和劣势。最后，探讨了LLMs在网络安全中的挑战、方向和未来可能的研究方向。

*链接：https://arxiv.org/pdf/2405.14487*


#### GPT-4 通过自我解释近乎完美地自我越狱

简介：本文提出了一种名为迭代细化诱导自我越狱（IRIS）的新方法，它利用大语言模型（LLMs）的反思能力，在黑盒环境下实现自我越狱。IRIS简化了越狱过程，通过自我解释迭代细化对抗性提示，确保模型遵循指令。该方法显著提高了越狱成功率，在GPT-4上达到98%，在GPT-4 Turbo上达到92%，且查询次数少于7次。IRIS在自动、黑盒和可解释的越狱方面超越了先前方法，为可解释越狱技术设立了新的标准。

*链接：https://arxiv.org/pdf/2405.13077*


#### 生成式人工智能与大语言模型在网络安全中的应用：需要了解的所有洞见

简介：本文全面审视了生成式人工智能和大语言模型（LLMs）在网络安全领域的未来应用。探讨了LLM在硬件安全、入侵检测、软件工程等多个关键领域的应用，并分析了包括GPT-4在内的先进模型。同时，研究了LLM的潜在漏洞和相应的缓解策略，评估了42种LLM模型在网络安全方面的表现。文章还讨论了数据集的生命周期管理，并提出了利用LLMs的新策略，如HQQ、RLHF等，旨在增强实时网络安全防御，并提高LLM在威胁检测和响应中应用的复杂性。最后，为将LLMs整合入未来网络安全框架提供了基础理解与战略方向，强调创新和模型的稳健部署以对抗不断演变的网络威胁。

*链接：https://arxiv.org/pdf/2405.12750*


#### 使用GPT的自动化硬件逻辑混淆框架

简介：本文介绍了Obfus-chat，一个利用生成式预训练变换器（GPT）模型自动化硬件逻辑混淆的框架。该框架接受硬件设计网表和密钥大小作为输入，自动生成增强安全性的混淆代码。通过Trust-Hub混淆基准和SAT攻击评估，结合功能验证，确保混淆设计与原始设计一致。结果表明，Obfus-chat在加强硬件知识产权防护方面既有效又高效，为硬件安全领域做出了重要贡献。

*链接：https://arxiv.org/pdf/2405.12197*




![secgeek-foot](https://www.gptsecurity.info/img/secgeek-foot.png)
