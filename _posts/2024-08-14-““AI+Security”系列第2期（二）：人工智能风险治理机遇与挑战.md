---
layout:     post
title:      "“AI+Security”系列第2期（二）：人工智能风险治理机遇与挑战"
date:       2024-08-14 19:00:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
tags:
    - Security
    - AIGC
    - “AI+Security”系列
  
---


![这是一张图片](https://www.gptsecurity.info/img/in-post/0807/01.jpg)
（加入“安全极客”知识星球，获取分享PPT等干货内容）

近日，由安全极客、Wisemodel 社区和 InForSec 网络安全研究国际学术论坛联合主办的“AI+Security”系列第 2 期——**对抗！大模型自身安全的攻防博弈**线上活动顺利举行。

活动期间，**君同未来创始人兼 CEO 韩蒙**发表了题为《**人工智能风险治理机遇与挑战**》的精彩演讲，深入探讨了大模型落地风险合规的要求与趋势，对生成式人工智能风险治理技术进行了展望，同时也剖析了人工智能产业发展所面临的挑战以及未来的机遇。

## 大模型落地风险合规要求与趋势

随着大模型的不断发展，人工智能技术进入了快速爆发阶段。自2017年谷歌推出Transformer神经网络架构以来，诸如 OpenAI 的 GPT 系列、百度的 ERNIE、华为的盘古大模型等多个重要的生成式人工智能模型相继涌现。2023年，OpenAI发布了具备图像识别能力的GPT-4，这标志着大模型技术获得了进一步的提升。然而，大模型在实际应用中也面临诸多风险，如数据中毒、隐私泄露以及生成内容违规等，给当前不断推进的人工智能落地过程带来了巨大挑战。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/05.jpg)

由于人工智能技术的快速发展和广泛应用，随之而来的是诸多安全风险，人工智能风险治理已经成为一项必须重视的任务。国家多个部委相继发布了关于人工智能治理及模型监管的相关规范和要求，制定了详细的法律法规和政策文件，以确保人工智能技术的安全性和合规性。此基础上，相关的国家标准和行业标准也在迅速推进中。这些标准的制定不仅有助于提升人工智能技术的安全性、可靠性和可控性，还能为行业从业者提供明确的技术规范和操作指南。标准的快速推进表明国家对人工智能安全问题的高度重视，同时也为企业和研究机构在技术研发和应用过程中提供了强有力的支撑。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/06.jpg)

此外，全球范围内的智能安全管理框架也在逐步形成与完善。国际组织和各国政府正积极合作，制定统一的技术标准和安全规范，以应对人工智能技术带来的跨国界风险。这些全球性的管理框架不仅有助于提升各国对人工智能技术的管控能力，还能促进国际间的技术交流与合作，推动全球人工智能技术的健康发展。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/07.jpg)

## 生成式人工智能风险治理技术展望

目前大语言模型面临的风险类型包括内生安全、伴生安全、应用安全问题。其中内生安全问题包括非对抗性风险、对抗性风险。非对抗性风险包含模型幻觉、数据偏见、机密数据泄露等；对抗性风险包括模型对抗攻击、模型越狱攻击、模型目标劫持攻击、模型提示词攻击等。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/08.jpg)

基于此，韩蒙博士表示，**君同未来深入探索了安全风险识别能力、攻击意图识别能力、正向回答生成能力、输出内容改写能力，并研发了三个安全技术平台，分别是大模型安全评测平台、大模型风险监控平台和大模型安全对齐平台，以提升大模型的安全性和可靠性**。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/09.jpg)

· **大模型安全评测平台**：这是一款专为大模型开发团队和监管机构打造的评测平台。它依据法规和行业标准构建合规测试题库，并运用内部变异分化风险测试技术，对模型进行安全合规性评估，以助力大模型测试人员快速测评模型的综合能力与安全合规状况，进而提升模型的安全性。该平台不仅集成了 150 个安全合规维度，还整合了 100 多种风险范式，能够实现从初步模型测试、开发测试到增强保护的一系列能力输出。在风险检测方面，平台支持链接接入、接口导入和程序导入等多种模型接入方式，确保对 50 多个子类的风险测试题进行有效覆盖，其标准远超国家现行的合规要求，为大模型的安全性提升筑牢了坚实基础。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/10.jpg)

· **大模型风险监控平台**：该平台致力于提供针对人工智能的安全性服务，借助平台内置的防御及检测手段，实现对人工智能模型的有效防御，保护人工智能系统和算法免遭恶意攻击、滥用、数据泄露以及不当访问等各类威胁。我们的风险监控系统具备实时捕捉潜在安全威胁并发出警告的能力，同时，自动化的漏洞修复功能能够确保对安全问题作出快速响应并进行有效处理。基于对不同应用场景合规要求的深入理解，平台达成了高度自动化的定制服务，保障了跨平台的兼容性，从而为用户给予全面的安全保障。此外，平台的风险监控功能涵盖从模型的输入端至输出端，通过自动化流程对风险予以清晰展示，进一步强化了我们产品的监测服务能力。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/11.jpg)

· **大模型安全对齐平台**：该平台可以监控扫描和记录大模型与用户交互过程中的所有输入和响应内容，并查找其中的风险内容，例如恶意代码或隐私信息。若发现此类内容，平台会自动阻止恶意输入并且自动改写恶意输出。同时，内置以RAG技术为核心的知识库模块，实现定制化大模型需求。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/12.jpg)

## 人工智能产业发展的挑战与未来机遇

伴随着人工智能技术的不断发展，韩蒙博士指出，AI市场未来的新赛道将涵盖大模型**代码生成、具身智能和AI Agent**三大趋势。这些技术在未来市场中展现了巨大的潜力和广泛的应用前景。随着技术的不断进步，它们将为各行各业带来深远的变革和提升。

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/13.jpg)


· **大模型代码生成**

大模型代码生成是当前软件开发过程中的核心技术之一，通过自动或半自动地创建源代码，显著提升开发效率与质量。传统的软件开发通常需要大量的人力投入，而大模型代码生成通过简易交互生成代码，能够重塑软件开发行业，减少对高成本开发人员的依赖，推动开发流程的全面革新。根据图表显示，从2023年到2033年，全球生成式AI在软件开发市场的规模预计将从40.8亿美元增长到160.3亿美元，市场总规模将达到1600亿美元。这一增长趋势表明，未来十年内，生成式AI将在软件开发领域发挥越来越重要的作用。

· **具身智能**

具身智能是人工智能与硬件结合的新兴领域，通过感知和交互与环境进行实时互动，实现直接的学习和应用。这种技术的发展为控制系统带来了革命性的智能提升，能够在现实世界中进行复杂的任务处理和决策。随着具身智能技术的广泛应用，风险管理和安全治理也将得到进一步加强。统计数据显示，从2018年到2033年，具身智能市场的年均增长率为9.1%，预计到2033年市场规模将达到8135.6亿美元，总市场规模将达到8100亿美元。这表明具身智能在未来的市场潜力巨大，将在多个领域发挥重要作用。

· **AI Agent**

AI Agent是一种将基础模型的推理能力与不同应用相结合的技术，通过调用不同的应用工具逐步完成特定目标。AI Agent能够赋予传统硬件应用智能，包括个性化推荐系统、内容生成与营销、硬件任务执行等，极大地扩展了AI的应用范围和能力。根据图表显示，从2021年到2032年，AI Agent市场的规模预计将从27亿美元增长到245亿美元，总市场规模将达到2000亿美元。这一数据表明，AI Agent在未来将成为推动多个行业智能化发展的关键力量。

## 写在最后

本文围绕大模型落地、技术展望以及未来产业发展进行了精彩的分享，使我们对大模型安全的相关内容有了更为丰富和深入的认识。未来，伴随着技术的持续发展进步以及企业的积极推动，大模型安全相关产业必将迎来更为重大的变革。

**“AI + Security”系列的第三期专题分享活动将于9月初左右与大家在线下见面**。届时，我们将邀请来自人工智能（AI）和网络安全领域的行业专家以及领军人物共同参与分享，深入探讨并分享关于“AI + Security”技术理念的独到见解和丰富经验。

欢迎大家**关注“安全极客”**，我们热切期待您的加入，一同推动AI与安全技术的融合与创新，共创美好未来！

![这是一张图片](https://www.gptsecurity.info/img/in-post/0814/14.jpg)

加入安全极客知识星球，获取嘉宾分享PPT等干货内容


