---
layout:     post
title:      "第55期|GPTSecurity周报"
date:       2024-06-17 12:00:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
catalog: true
tags:
    - Security
    - AIGC
    - GPTSecurity周报
---

GPTSecurity是一个涵盖了前沿学术研究和实践经验分享的社区，集成了生成预训练Transformer（GPT）、人工智能生成内容（AIGC）以及大语言模型（LLM）等安全领域应用的知识。在这里，您可以找到关于GPT/AIGC/LLM最新的研究论文、博客文章、实用的工具和预设指令（Prompts）。现为了更好地知悉近一周的贡献内容，现总结如下。

## **Security Papers**

1. REVS: 通过词汇空间中的排名编辑在语言模型中消除敏感信息

  简介：大语言模型（LLMs）可能无意中记住并泄露训练数据中的敏感信息，引发隐私担忧。为解决此问题，研究者提出了一种名为REVS的创新模型编辑技术。该技术通过识别和修改与敏感信息相关的神经元子集来消除这些信息。REVS将这些神经元映射到词汇空间，以确定生成敏感内容的关键组件，并通过计算反嵌入矩阵的伪逆来编辑模型，从而减少敏感数据的生成。研究者通过电子邮件数据集和合成的社会保障号码数据集这两个数据集，验证了REVS的有效性。结果表明，REVS在消除敏感信息和抵御提取攻击方面表现出色，同时保持了模型的完整性。

  链接：

  *https://arxiv.org/pdf/2406.09325*

2. 人工智能作为新黑客：开发用于进攻性安全的智能体

  简介：在网络安全领域，人工智能（AI）技术正被用于开发自主攻击代理ReaperAI，以模拟和执行网络攻击。通过利用大语言模型如GPT-4的能力，ReaperAI能够自主识别和利用安全漏洞。在多个平台上的测试表明，ReaperAI成功利用已知漏洞，展示了其在进攻性安全策略中的潜力。然而，AI在进攻性安全中的应用也引发了伦理和操作上的挑战，包括命令执行、错误处理和伦理约束。本研究强调了AI在网络安全中创新应用的重要性，并提出了未来研究方向，包括AI与安全工具的交互优化、学习机制的提升以及伦理指导方针的讨论。

  链接：

  *https://arxiv.org/abs/2406.07561*

3. 利用大语言模型（LLM）辅助的代码补全模型易触发后门攻击：注入伪装的漏洞以对抗强检测

简介：大语言模型（LLMs）在软件工程中通过提供上下文建议显著提高了代码补全的效率。然而，这些模型在特定应用中的微调可能遭受中毒和后门攻击，导致输出被秘密篡改。为应对这一安全威胁，研究者提出了CodeBreaker，这是一个利用LLMs（如GPT-4）进行复杂载荷转换的后门攻击框架，确保中毒数据和生成代码能够绕过强漏洞检测。CodeBreaker通过直接将恶意载荷集成到源代码中，挑战了现有的安全措施，凸显了对代码补全系统加强防御的必要性。实验和用户研究证实了CodeBreaker在不同环境下的攻击效能，证明了其在现有方法中的优越性。

链接：

*https://arxiv.org/abs/2406.06822*

4. SecureNet: DeBERTa与大语言模型在钓鱼检测中的比较研究

  简介：在网络安全领域，钓鱼攻击通过社会工程学手段诱骗用户泄露敏感信息，对组织构成重大威胁。本文探讨了大语言模型（LLMs）在检测钓鱼内容方面的潜力，并与DeBERTa V3模型进行了比较。通过使用包括电子邮件、HTML、URL、短信和合成数据在内的公共数据集，研究者系统地评估了这些模型的性能和局限性。

  研究发现，基于Transformer的DeBERTa模型在检测钓鱼内容方面表现最佳，其召回率高达95.17%，而GPT-4的召回率为91.04%。此外，研究者还探讨了这些模型在生成钓鱼邮件方面的挑战，并评估了它们在这一背景下的性能。研究结果为未来加强网络安全措施提供了宝贵的见解，有助于更有效地检测和应对钓鱼威胁。

  链接：

  *https://arxiv.org/abs/2406.06663*

5. 探索大语言模型（GPT-4）在二进制逆向工程中的有效性

  简介：本研究探讨了大语言模型（LLMs），特别是GPT-4，在二进制逆向工程（RE）领域的应用能力。通过结构化的实验方法，研究者分析了LLMs在解释人类编写的和反编译的代码方面的性能。研究包括两个阶段：第一个阶段关注基本代码解释，第二个阶段则涉及更复杂的恶意软件分析。关键发现表明，LLMs在一般代码理解方面表现出色，但在详细的技术和安全分析方面效果各异。

  研究强调了LLMs在逆向工程中的潜力和当前的局限性，为未来应用和改进提供了关键的见解。此外，研究者还检查了实验方法，如评估方法和数据限制，为研究者未来在此领域的研究活动提供了技术视野。

  链接：

  *https://arxiv.org/abs/2406.06637*

6. OccamLLM：单步快速精确语言模型算术

  简介：为了提高大语言模型（LLMs）在执行复杂算术运算时的准确性，研究者提出了一种新框架，该框架允许在单个自回归步骤中进行精确的算术运算。通过利用LLM的隐藏状态来控制符号架构，研究者的方法在单个算术运算上达到了100%的准确率，与GPT-4相当，甚至在多步骤推理问题上也超过了Llama 3 8B Instruct和GPT-3.5 Turbo。该方法不仅提高了速度和安全性，还保持了LLM的原有能力。研究者计划不久后公开代码，以促进更广泛的研究和应用。

  链接：

  *https://arxiv.org/abs/2406.06576*



![secgeek-foot](https://www.gptsecurity.info/img/secgeek-foot.png)
