---
layout:     post
title:      "第51期｜GPTSecurity周报"
date:       2024-05-13 12:00:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
tags:
    - Security
    - AIGC
    - GPT周报
---

GPTSecurity是一个涵盖了前沿学术研究和实践经验分享的社区，集成了生成预训练Transformer（GPT）、人工智能生成内容（AIGC）以及大语言模型（LLM）等安全领域应用的知识。在这里，您可以找到关于GPT/AIGC/LLM最新的研究论文、博客文章、实用的工具和预设指令（Prompts）。现为了更好地知悉近一周的贡献内容，现总结如下。

## Security Papers

- **6G全面智能：基于大语言模型的网络运营和优化**

  **简介：**本文提出了基于大语言模型（LLM）的6G网络性能优化和智能运营架构，旨在构建全面的智能网络系统，以促进工业互联网和物联网的发展。LLM凭借其强大的学习能力，能更准确捕捉数据特征，为网络数据安全、隐私保护等提供支持。文章还介绍了基于LLM的网络健康评估系统框架，并通过案例展示了其在实现网络智能化中的重要作用。

  **链接：**https://arxiv.org/pdf/2404.18373

- **地理空间大数据：调查与挑战**

  **简介：**本文探讨了地理空间大数据（GBD）在城市管理和环境可持续性研究中的应用，以及其与人工智能技术的结合。GBD数据来源多样，包括卫星、传感器等，通过不同角度分类。文章概述了GBD挖掘流程，并讨论了如何整合新技术如大语言模型、元宇宙和知识图谱来增强其效用。同时，分享了GBD在城市和环境保护中的应用案例，并指出了数据检索和安全等挑战，旨在为读者提供GBD挖掘当前状态和未来趋势的清晰视角。

  **链接：**https://arxiv.org/pdf/2404.18428

- **评估代码大语言模型的网络安全漏洞**

  **简介：**本文介绍了EvilInstructCoder框架，旨在评估指令调优的代码大语言模型（Code LLMs）在对抗性攻击下的网络安全漏洞。该框架通过自动生成恶意代码片段并注入良性代码，模拟现实世界中的不同威胁模型，评估Code LLMs的可利用性。实验使用了CodeLlama、DeepSeek-Coder和StarCoder2三个模型，发现即使在数据集中仅注入少量恶意样本，也能显著提高攻击成功率。研究结果突显了Code LLMs的安全隐患，强调了开发强大防御机制以应对这些漏洞的紧迫性。

  **链接：**https://arxiv.org/pdf/2404.18567

- **AppPoet：基于大语言模型的多视角提示工程进行Android恶意软件检测**

  **简介：**AppPoet是一个基于大语言模型（LLM）的多视角Android恶意软件检测系统。它首先通过静态方法全面收集应用特征，构建不同观察视角，然后利用LLM和多视角提示工程技术生成功能描述和行为摘要，深度挖掘语义信息。最后，通过深度神经网络（DNN）分类器融合多视角信息，高效准确地检测恶意软件，并生成启发式诊断报告。实验结果显示，该方法检测准确率达97.15%，F1分数为97.21%，优于现有方法，并能生成有效的诊断报告。

  **链接：**https://arxiv.org/pdf/2404.18816

- **转移麻烦：具有指令调优的大语言模型中后门攻击的跨语言可转移性**

  **简介：**本研究探讨了多语言大语言模型（LLMs）的跨语言后门攻击，特别是研究了在一种或两种语言中投毒指令调优数据如何影响未被投毒语言的输出。研究发现，即使在模型规模增大的情况下，跨语言后门攻击的成功率依然超过95%，且在25种语言中平均达到50%。研究强调了当前多语言LLMs存在的安全风险，并指出了针对性安全措施的迫切需求。

  **链接：** https://arxiv.org/pdf/2404.19597

- **用于安全代码生成的约束解码**

  **简介：**本文提出了CodeGuard+基准测试和两个新指标，以衡量代码大语言模型（Code LLMs）生成安全且正确代码的能力。研究发现，当前领先的防御技术前缀调整虽然能生成安全代码，但牺牲了功能正确性。文章还探讨了约束解码技术，用以生成同时满足安全性和正确性约束的代码，该方法比前缀调整更有效，且无需专门的训练数据集，可以进一步提高Code LLMs的安全性。

  **链接：**https://arxiv.org/pdf/2405.00218





![secgeek-foot](https://www.gptsecurity.info/img/secgeek-foot.png)
