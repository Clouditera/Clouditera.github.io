---
description: 在安全领域应用GPT/AIGC/LLM的论文以及博文
---

# Security Papers

## 行业新闻

1. 微软宣布推出网络安全产品——**Microsoft Security Copilot**\
   Security Copilot将目前最强大语言模型GPT-4内置在产品中，并与微软拥有65万亿个网络安全威胁的安全模型库相结合使用，为企业、个人用户提供网络安全、恶意代码防护、隐私合规监控等生成式自动化AI服务\
   [https://thehackernews.com/2023/03/microsoft-introduces-gpt-4-ai-powered.html](https://thehackernews.com/2023/03/microsoft-introduces-gpt-4-ai-powered.html)
2. 在网络安全最佳实践中集成ChatGPT和生成式AI\
   [https://www.sentinelone.com/blog/integrating-chatgpt-generative-ai-within-cybersecurity-best-practices/](https://www.sentinelone.com/blog/integrating-chatgpt-generative-ai-within-cybersecurity-best-practices/)
3. 行业分析：云之后，大模型是网络安全的新机会吗？\
   [https://mp.weixin.qq.com/s/nmeDrQX5dTRUT23-2sGI-g](https://mp.weixin.qq.com/s/nmeDrQX5dTRUT23-2sGI-g)
4. VirusTotal推出Code Insight，用生成式人工智能为威胁分析赋能\
   [https://blog.virustotal.com/2023/04/introducing-virustotal-code-insight.html](https://blog.virustotal.com/2023/04/introducing-virustotal-code-insight.html)
5. 安全大模型进入爆发期！谷歌云已接入全线安全产品｜RSAC 2023\
   [https://mp.weixin.qq.com/s/5Aywrqk7B6YCiLRbojNCuQ](https://mp.weixin.qq.com/s/5Aywrqk7B6YCiLRbojNCuQ)
6. Facebook季度安全报告：假冒ChatGPT的恶意软件激增 \
   [https://about.fb.com/news/2023/05/metas-q1-2023-security-reports/](https://about.fb.com/news/2023/05/metas-q1-2023-security-reports/)
7. Tenable的报告展示了生成式人工智能正在如何改变安全研究 \
   [https://venturebeat.com/security/tenable-report-shows-how-generative-ai-is-changing-security-research/](https://venturebeat.com/security/tenable-report-shows-how-generative-ai-is-changing-security-research/)

## 软件供应链安全

{% hint style="info" %}
利用GPT/AIGC/LLM来进行漏洞挖掘和修复、代码质量评测、程序理解
{% endhint %}

### 论文

1. Detecting software vulnerabilities using Language Models\
   [https://arxiv.org/ftp/arxiv/papers/2302/2302.11773.pdf](https://arxiv.org/ftp/arxiv/papers/2302/2302.11773.pdf)
2. Evaluation of ChatGPT Model for Vulnerability Detection\
   [https://arxiv.org/pdf/2304.07232.pdf](https://arxiv.org/pdf/2304.07232.pdf)
3. LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluation\
   [https://arxiv.org/pdf/2303.09384.pdf](https://arxiv.org/pdf/2303.09384.pdf)
4. DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection\
   [https://arxiv.org/pdf/2304.00409.pdf](https://arxiv.org/pdf/2304.00409.pdf)
5. Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT\
   [https://arxiv.org/pdf/2304.02014.pdf](https://arxiv.org/pdf/2304.02014.pdf)
6. Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models\
   [https://arxiv.org/pdf/2212.14834.pdf](https://arxiv.org/pdf/2212.14834.pdf)
7. InferFix: End-to-End Program Repair with LLMs\
   [https://arxiv.org/pdf/2303.07263.pdf](https://arxiv.org/pdf/2303.07263.pdf)
8. Fixing Hardware Security Bugs with Large Language Models\
   [https://arxiv.org/pdf/2302.01215.pdf](https://arxiv.org/pdf/2302.01215.pdf)
9. Generating Secure Hardware using ChatGPT Resistant to CWEs \
   围绕硬件设计实施常见的10个CWE，分别展示了生成带缺陷代码和安全代码的提示词场景 \
   [https://eprint.iacr.org/2023/212.pdf](https://eprint.iacr.org/2023/212.pdf)
10. Examining Zero-Shot Vulnerability Repair with Large Language Models\
   [https://arxiv.org/pdf/2112.02125.pdf](https://arxiv.org/pdf/2112.02125.pdf)
11. Practical Program Repair in the Era of Large Pre-trained Language Models\
   [https://arxiv.org/pdf/2210.14179.pdf](https://arxiv.org/pdf/2210.14179.pdf)
12. An Analysis of the Automatic Bug Fixing Performance of ChatGPT\
    [https://arxiv.org/pdf/2301.08653.pdf](https://arxiv.org/pdf/2301.08653.pdf)
13. Automatic Program Repair with OpenAI's Codex: Evaluating QuixBugs\
    [https://arxiv.org/pdf/2111.03922.pdf](https://arxiv.org/pdf/2111.03922.pdf)
14. Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions\
    [https://arxiv.org/pdf/2108.09293.pdf](https://arxiv.org/pdf/2108.09293.pdf)
15. Do Users Write More Insecure Code with AI Assistants?\
    [https://arxiv.org/pdf/2211.03622.pdf](https://arxiv.org/pdf/2211.03622.pdf)
16. How Secure is Code Generated by ChatGPT?\
    [https://arxiv.org/pdf/2304.09655.pdf](https://arxiv.org/pdf/2304.09655.pdf)
17. Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants\
    [https://arxiv.org/pdf/2208.09727.pdf](https://arxiv.org/pdf/2208.09727.pdf)
18. Evaluating Large Language Models Trained on Code\
    [https://arxiv.org/pdf/2107.03374.pdf](https://arxiv.org/pdf/2107.03374.pdf)
19. Assessing the Quality of GitHub Copilot's Code Generation\
    [https://dl.acm.org/doi/abs/10.1145/3558489.3559072](https://dl.acm.org/doi/abs/10.1145/3558489.3559072)
20. Is GitHub's Copilot as Bad as Humans at Introducing Vulnerabilities in Code?\
    [https://arxiv.org/pdf/2204.04741.pdf](https://arxiv.org/pdf/2204.04741.pdf)
21. Teaching Large Language Models to Self-Debug\
    [https://arxiv.org/pdf/2304.05128.pdf](https://arxiv.org/pdf/2304.05128.pdf)
22. Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT \
    [https://arxiv.org/pdf/2304.10778.pdf](https://arxiv.org/pdf/2304.10778.pdf)
23. Fault-Aware Neural Code Rankers\
    [https://arxiv.org/pdf/2206.03865.pdf](https://arxiv.org/pdf/2206.03865.pdf)
24. Using Large Language Models to Enhance Programming Error Messages\
    [https://arxiv.org/pdf/2210.11630.pdf](https://arxiv.org/pdf/2210.11630.pdf)
25. Controlling Large Language Models to Generate Secure and Vulnerable Code\
    引用了Asleep at the keyboard? 使用了预训练模型，对LM的输出进行pre-train以控制输出的代码是安全的还是存在漏洞的\
    [https://arxiv.org/pdf/2302.05319.pdf](https://arxiv.org/pdf/2302.05319.pdf)
26. Systematically Finding Security Vulnerabilities in Black-Box Code Generation Models\
    针对“prompt中的微小变化可能导致漏洞”的问题，在"Asleep at the keyboard?"手动操作在基础上实现自动化发现\
    [https://arxiv.org/pdf/2302.04012.pdf](https://arxiv.org/pdf/2302.04012.pdf)
27. SecurityEval Dataset: Mining Vulnerability Examples to Evaluate Machine Learning-Based Code Generation Techniques\
    在Systematically Finding Security Vulnerabilities in Black-Box Code Generation的论文中，把这篇轮看的很重，解决模型评估的数据集的问题\
    [https://dl.acm.org/doi/abs/10.1145/3549035.3561184](https://dl.acm.org/doi/abs/10.1145/3549035.3561184)
28. Pop Quiz! Can a Large Language Model Help With Reverse Engineering\
    [https://arxiv.org/pdf/2202.01142.pdf](https://arxiv.org/pdf/2202.01142.pdf)
29. CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models\
    微软在ICSE2023上发布的论文，旨在利用LLM来缓解传统fuzz中的陷入“Coverage Plateaus”的问题\
    [https://www.carolemieux.com/codamosa_icse23.pdf](https://www.carolemieux.com/codamosa_icse23.pdf)

### 博客

1. 用GPT做静态代码扫描实现自动化漏洞挖掘思路分享\
   [https://mp.weixin.qq.com/s/Masyfq12cjaM4Zn6qxvGoA](https://mp.weixin.qq.com/s/Masyfq12cjaM4Zn6qxvGoA)
2. 用 LLM 降低白盒误报及自动修复漏洞代码\
   [https://mp.weixin.qq.com/s/leLFECUaNOGbjsN\_8mcXrQ](https://mp.weixin.qq.com/s/leLFECUaNOGbjsN\_8mcXrQ)
3. ChatGPT在源代码分析中可靠吗？\
   [https://mp.weixin.qq.com/s/Ix2lArBzaCAJr5nyGolCwQ](https://mp.weixin.qq.com/s/Ix2lArBzaCAJr5nyGolCwQ)
4. ChatGPT在代码中定位缺陷足够好吗？\
   [https://pvs-studio.com/en/blog/posts/1035/](https://pvs-studio.com/en/blog/posts/1035/)
5. ChatGPT+RASP，实现CodeQL漏洞挖掘高效自动化\
   [https://mp.weixin.qq.com/s/xlUWn2oWU51NVkgB157pRw](https://mp.weixin.qq.com/s/xlUWn2oWU51NVkgB157pRw)
6. ChatGPTScan:使用ChatGPTScan批量进行代码审计\
   [https://mp.weixin.qq.com/s/QIKvRzNlAKiqh\_UMOMfDdg](https://mp.weixin.qq.com/s/QIKvRzNlAKiqh\_UMOMfDdg)
7. 应用GPT-4 于 Semgrep 中以指出误报和修复代码\
   [https://semgrep.dev/blog/2023/gpt4-and-semgrep-detailed?utm\_source=twitter\&utm\_medium=social\&utm\_campaign=brand](https://semgrep.dev/blog/2023/gpt4-and-semgrep-detailed?utm\_source=twitter\&utm\_medium=social\&utm\_campaign=brand)
8. Kondukto产品利用OpenAI来修复代码漏洞\
   [https://kondukto.io/blog/kondukto-openai-chatgpt](https://kondukto.io/blog/kondukto-openai-chatgpt)
9. 利用ChatGPT来进行代码审计\
   [https://research.nccgroup.com/2023/02/09/security-code-review-with-chatgpt/](https://research.nccgroup.com/2023/02/09/security-code-review-with-chatgpt/)
10. 利用GPT-3在单个代码仓库中找到213个安全漏洞\
    [https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)
11. 利用GPT-4进行调试和漏洞修复\
    [https://www.sitepoint.com/gpt-4-for-debugging/](https://www.sitepoint.com/gpt-4-for-debugging/)
12. 黑客可能利用ChatGPT的方式\
    [https://cybernews.com/security/hackers-exploit-chatgpt/](https://cybernews.com/security/hackers-exploit-chatgpt/)
13. GPT-4 Jailbreak and Hacking via Rabbithole Attack, Prompt Injection, Content Modderation Bypass and Weaponizing AI\
    [https://adversa.ai/blog/gpt-4-hacking-and-jailbreaking-via-rabbithole-attack-plus-prompt-injection-content-moderation-bypass-weaponizing-ai/](https://adversa.ai/blog/gpt-4-hacking-and-jailbreaking-via-rabbithole-attack-plus-prompt-injection-content-moderation-bypass-weaponizing-ai/)
14. 我是如何用GPT自动化生成Nuclei的POC\
    [https://mp.weixin.qq.com/s/Z8cTUItmbwuWbRTAU\_Y3pg](https://mp.weixin.qq.com/s/Z8cTUItmbwuWbRTAU\_Y3pg)

## 威胁检测

{% hint style="info" %}
利用GPT/AIGC/LLM来完成恶意软件、网络攻击等威胁检测
{% endhint %}

### 论文

1. Static Malware Detection Using Stacked BiLSTM and GPT-2\
   [https://ieeexplore.ieee.org/document/9785789](https://ieeexplore.ieee.org/document/9785789)

### 博客

1. IoC detection experiments with ChatGPT\
   [https://securelist.com/ioc-detection-experiments-with-chatgpt/108756/](https://securelist.com/ioc-detection-experiments-with-chatgpt/108756/)
2. ChatGPT赋能的威胁分析——使用ChatGPT为每个npm, PyPI包检查安全问题，包括信息渗透、SQL注入漏洞、凭证泄露、提权、后门、恶意安装、预设指令污染等威胁\
   [https://socket.dev/blog/introducing-socket-ai-chatgpt-powered-threat-analysis](https://socket.dev/blog/introducing-socket-ai-chatgpt-powered-threat-analysis)

## 安全运营
{% hint style="info" %}
利用GPT/AIGC/LLM来辅助安全运营/SOAR/SIEM
{% endhint %}

### 论文

1. GPT-2C: A GPT-2 Parser for Cowrie Honeypot Logs \
   [https://arxiv.org/pdf/2109.06595.pdf](https://arxiv.org/pdf/2109.06595.pdf)

### 博客

1. Elastic公司发布的"与ChatGPT探索安全的未来" \
   提出了6个构想：(1) 聊天机器人协助事件响应 (2) 威胁报告生成 (3) 自然语言检索 (4) 异常检测 (5) 安全策略问答机器人 (6) 告警排序。 \
   [https://www.elastic.co/cn/security-labs/exploring-applications-of-chatgpt-to-improve-detection-response-and-understanding](https://www.elastic.co/cn/security-labs/exploring-applications-of-chatgpt-to-improve-detection-response-and-understanding)
2. ChatGPT在安全运营中的应用初探 \
   结论——ChatGPT可以赋能包括事件分析与响应在内的多种安全运营过程，降低对本就不足的预置安全知识的依赖，并能促进有价值的安全知识的产生和积累，从而帮助安全运营团队更准确地做出决策、实施响应、积累经验，尤其对初级安全工程师有辅导作用。当然，现阶段以及未来一段时间，ChatGPT等高级AI驱动的聊天机器人还无法完全取代人类分析师，更多是提供辅助决策与操作支持。相信随着持续高强度的人机会话互动，再借助更大规模更专业（网络安全运营领域）的语料库训练，ChatGPT会不断强化自己的能力，不断减轻人类安全分析师的工作负担。 \
   [https://www.secrss.com/articles/51775](https://www.secrss.com/articles/51775)
3. 利用Chat GPT和D3的AI辅助事件响应 \
   探讨将ChatGPT与Smart SOAR整合的好处；提供样例分析——使用MITRE TTPs和微软端点防御系统警报中发现的恶意软件家族以收集事件的背景信息，之后问ChatGPT，让它根据对TTP和恶意软件的了解，描述攻击者接下来可能会采取什么措施、恶意软件可能利用什么漏洞。 \
   [https://www.163.com/dy/article/I48DBHHG055633FJ.html](https://www.163.com/dy/article/I48DBHHG055633FJ.html)


## GPT自身安全

{% hint style="info" %}
关于GPT/AIGC/LLM等大模型技术自身的各类安全风险以及漏洞，大模型技术滥用与误用的可能性
{% endhint %}

### 论文

1. GPT-4 Technical Report\
   OpenAI对模型自身安全评估和缓解\
   [https://arxiv.org/abs/2303.08774](https://arxiv.org/pdf/2303.08774.pdf)
2. Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models\
   提出一个未来的研究方向：在特定的使用情境下，保障大语言模型的安全可靠性需要发展什么类型的测试？\
   [https://arxiv.org/pdf/2102.02503.pdf](https://arxiv.org/pdf/2102.02503.pdf)
3. Taxonomy of Risks posed by Language Models\
   [https://dl.acm.org/doi/10.1145/3531146.3533088](https://dl.acm.org/doi/10.1145/3531146.3533088)
4. The (ab)use of Open Source Code to Train Large Language Models\
   [https://arxiv.org/pdf/2302.13681.pdf](https://arxiv.org/pdf/2302.13681.pdf)
5. In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT\
   [https://arxiv.org/pdf/2304.08979.pdf](https://arxiv.org/pdf/2304.08979.pdf)
6. Ignore Previous Prompt: Attack Techniques For Language Models\
   ML Safety Workshop NeurIPS 2022，以及提示注入的开山之作\
   [https://arxiv.org/pdf/2211.09527.pdf](https://arxiv.org/pdf/2211.09527.pdf)
7. Boosting Big Brother: Attacking Search Engines with Encodings \
   攻击测试了集成OpenAI GPT-4模型的必应搜索引擎 \
   [https://arxiv.org/pdf/2304.14031.pdf](https://arxiv.org/pdf/2304.14031.pdf)
8. More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models\
   间接提示注入的开山之作，里面很多场景都已成为现实\
   [https://arxiv.org/pdf/2302.12173.pdf](https://arxiv.org/pdf/2302.12173.pdf)
9. RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models\
   [https://arxiv.org/pdf/2009.11462.pdf](https://arxiv.org/pdf/2009.11462.pdf)
10. Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks\
      [https://arxiv.org/pdf/2302.05733.pdf](https://arxiv.org/pdf/2302.05733.pdf)
11. Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection \
    [https://arxiv.org/pdf/2302.12173.pdf](https://arxiv.org/pdf/2302.12173.pdf)
12. Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned \
    [https://arxiv.org/pdf/2209.07858.pdf](https://arxiv.org/pdf/2209.07858.pdf)
13. Beyond the Safeguards: Exploring the Security Risks of ChatGPT \
    [https://arxiv.org/pdf/2305.08005.pdf](https://arxiv.org/pdf/2305.08005.pdf)
14. Can We Generate Shellcodes via Natural Language? An Empirical Study\
    [https://link.springer.com/article/10.1007/s10515-022-00331-3](https://link.springer.com/article/10.1007/s10515-022-00331-3)

### 博客

1. 干货分享！Langchain框架Prompt Injection在野0day漏洞分析\
   [https://mp.weixin.qq.com/s/wFJ8TPBiS74RzjeNk7lRsw](https://mp.weixin.qq.com/s/wFJ8TPBiS74RzjeNk7lRsw)
2. 通过提示注入在 MathGPT 中实现代码执行 \
   公开可用的 MathGPT 借助底层的GPT-3模型来回答用户生成的数学问题。最近的研究和实验表明，GPT-3 等 大模型在直接进行数学计算的任务上表现不佳，然而能够更准确地生成问题解决方案的可执行代码。 因此 MathGPT 将用户的自然语言问题转换为 Python 代码，执行计算后的代码和答案会显示给用户。某些 LLM 可能容易受到提示词注入攻击，恶意用户输入会导致模型执行意外行为\[3]\[4]。 在此事件中，攻击者探索了几种提示词覆盖途径，生成的代码最终导致攻击者获得应用程序主机系统的环境变量和应用程序的 GPT-3 API 密钥的访问权限，并执行拒绝服务攻击。 因此，攻击者可能会耗尽应用程序的 API 查询预算或关闭应用程序。\
   [https://atlas.mitre.org/studies/AML.CS0016/](https://atlas.mitre.org/studies/AML.CS0016/)
3. 用ChatGPT来生成编码器与配套WebShell\
   antsword官方出品\
   [https://mp.weixin.qq.com/s/I9IhkZZ3YrxblWIxWMXAWA](https://mp.weixin.qq.com/s/I9IhkZZ3YrxblWIxWMXAWA)
4. 使用ChatGPT来生成钓鱼邮件和钓鱼网站\
   相比其他仅生成钓鱼邮件，这里把钓鱼网站也生成了\
   [https://www.richardosgood.com/posts/using-openai-chat-for-phishing/](https://www.richardosgood.com/posts/using-openai-chat-for-phishing/)
5. Chatting Our Way Into Creating a Polymorphic Malware\
   [https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware](https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware)
6. Hacking Humans with AI as a Service\
   [https://media.defcon.org/DEF%20CON%2029/DEF%20CON%2029%20presentations/Eugene%20Lim%20Glenice%20Tan%20Tan%20Kee%20Hock%20-%20Hacking%20Humans%20with%20AI%20as%20a%20Service.pdf](https://media.defcon.org/DEF%20CON%2029/DEF%20CON%2029%20presentations/Eugene%20Lim%20Glenice%20Tan%20Tan%20Kee%20Hock%20-%20Hacking%20Humans%20with%20AI%20as%20a%20Service.pdf)
7. 内建虚拟机实现ChatGPT的越狱\
   [https://www.engraved.blog/building-a-virtual-machine-inside/](https://www.engraved.blog/building-a-virtual-machine-inside/)
8. ChatGPT can boost your Threat Modeling skills\
   [https://infosecwriteups.com/chatgpt-can-boost-your-threat-modeling-skills-ab82149d0140](https://infosecwriteups.com/chatgpt-can-boost-your-threat-modeling-skills-ab82149d0140)
9. Using GPT-Eliezer against ChatGPT Jailbreaking \
   检测对抗性提示词 \
   [https://www.alignmentforum.org/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking](https://www.alignmentforum.org/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking)
10. LLM中的安全隐患-以VirusTotal Code Insight中的提示注入为例\
   [https://mp.weixin.qq.com/s/U2yPGOmzlvlF6WeNd7B7ww](https://mp.weixin.qq.com/s/U2yPGOmzlvlF6WeNd7B7ww)

## 以安全数据训练GPT

{% hint style="info" %}
收集安全数据训练或增强GPT/AIGC/LLM等大模型技术
{% endhint %}

### 论文

1. Web Content Filtering through knowledge distillation of Large Language Models \
   [https://arxiv.org/pdf/2305.05027.pdf](https://arxiv.org/pdf/2305.05027.pdf)

### 博客

1. ChatGPT：和黑客知识库聊天 \
   (1) 从prompt到自训练数据原文反向索引的准确性；(2) openai提供模型的微调服务的尝试；(3) 其他可替代性模型总结；(4) 围绕markdown格式的数据集解析和分块索引的脚本示例； (5) 相似索引向量引擎推荐。 \
   [https://mp.weixin.qq.com/s/dteH4oP24qGY-4l3xSl7Vg](https://mp.weixin.qq.com/s/dteH4oP24qGY-4l3xSl7Vg)
2. 如何训练自己的“安全大模型” \
   [https://mp.weixin.qq.com/s/801sV5a7-wOh_1EN3U64-Q](https://mp.weixin.qq.com/s/801sV5a7-wOh_1EN3U64-Q)
